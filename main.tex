\tableofcontents
\clearpage

\section{Literature Review and Background}
% MoC in neutronics
% SN in neutronics
% global illumination in computer graphics
%       goals, algorithms

%%%%%%
% Nathans thoughts on the layout of this section:
% - Neutron Transport equation presentation, and discussion
% - Numerical methods to solving neutron transport equation (Pn, Sn, short vs long MOC, Diffusion)
    % strengths, weaknesses, applications
% - Discussion of MOC specifically, presentation of basic MOC ideas and equations (flat vs linear source region, TRRM, parallelism...)
% - Related fields to neutron transport (global illumination in computer graphics, non-LTE radiative transfer)
    %  methods in solving there, finish with Radiance Cascades
%%%%%%
\subsection{Global Deterministic Methods in Neutron Transport}
\subsection{Global Illumination in Computer Graphics}

\section{Radiance Cascades}
\subsection{Penumbra Criteria}
\subsubsection{Penumbra Criteria for Global Illumination}\label{subsubsec:penumber-gi}
% Nathan
The relationship between the distance from a source and the required spatial and angular resolution to resolve the source is the `penumbra condition'.
The penumbra condition is formally defined by Sannikov~\cite{sannikovRadianceCascadesNovel} using a 2-D planar problem with a light source and perfectly opaque absorber. 
The goal of the problem is to determine the angular and spatial resolution required to accurately capture the penumbra of the shadow cast by the source at some distance past the absorber.

This can be illustrated by considering a detector placed in the penumbra.
When the detector is near the source and absorber, moving the detector laterally will expose a significant additional amount of the source to the detector. 
Inversely, if the detector is far, the lateral step required to yield the same change in the exposure of the source is much greater. 
Therefore the number of lateral steps required to resolve the source is related to the distance from it, so as the distance increases, the lateral step size ($\Delta_s$) can also be increased. 
Next, the solid angle of the source and absorber, when the detector is close, is large, and so a small angular shift in the direction of the detector face will not yield a large change in the perceived solid angle.
Conversely, far from the source and absorber, the solid angle is small, and so a small angular shift can result in a large change in the perceived solid angle.
Thus, the number of angular steps required to resolve the source is inversely related to the distance, and so as the distance increases, the angular step size ($\Delta_{\omega}$) must decrease.

Compressing these observations yields the penumbra condition~\cite{sannikovRadianceCascadesNovel, osborneRadianceCascadesNovel2025}:
\begin{enumerate}
    \item Near-field radiance contributions from the light source vary with high spatial frequency and low angular frequency.
    \item Far-field radiance contributions from the light source vary with low spatial frequency and high angular frequency.
\end{enumerate}

The penumbra condition can be represented mathematically as~\cite{sannikovRadianceCascadesNovel, osborneRadianceCascadesNovel2025}:
\begin{align}
    \begin{split}
        \Delta_s &< f(D) \propto D,\\
        \Delta_{\omega} &< g(D) \propto 1/D,
    \end{split}
\end{align}

such that $f(D)$ and $g(D)$ are linear functions of the distance $D$ from a source. It should be noted that these observations still hold for the case in which the source is far from the absorber, but for that case the angular step $\Delta_{\omega}$ scales super-linearly with $1/D$~\cite{osborneRadianceCascadesNovel2025}. 

\glspl{rc} depends on the hypothesis that the penumbra condition holds generally throughout the problem domain for all sources. 
There are trivial exceptions to this hypothesis, namely a point source or a small source embedded in a perfectly absorbing medium. 
In general however, the penumbra condition holds well for most purposes, and \glspl{rc} are formulated to encode most extreme cases~\cite{sannikovRadianceCascadesNovel}.

\subsubsection{Formalization of the Penumbra Criteria}
% Liam
As discussed in \cref{subsubsec:penumber-gi}, the penumbra criteria was originally formulated for global illumination problems in video game development.
As such, the motivations for its formulation differ from those in the scientific community.
That is, greater emphasis is placed on the \textit{speed} of the algorithm, rather than the numerical accuracy. 
This is clearly seen in the penumbra criteria, which lacks rigor in its definition.
Indeed, though initial papers by Sannikov and Osborne acknowledge the proportionality of the required step size needed in the angular and spatial discretizations, neither attempt to describe additional constraints to the requirements; both papers simply assume a coefficient of 1 and boldly claim that this holds generally.
As part of this work, we propose to formalize the penumbra criteria so that the \glspl{rc} technique and its limitations are clearly understood.

For example, as seen in~\cite{sannikovRadianceCascadesNovel} and~\cite{osborneRadianceCascadesNovel2025}, the penumbra criteria assume the flux solution within the transition region is approximately linear between probes.
This is clearly seen in the small angle approximation to the tangent function in \cref{subsubsec:penumber-gi}.

\subsection{Radiance Intervals}
% Nathan
% What is it, definition/derivation, interval merging
This section introduces and derives the concept of radiance intervals in a neutron transport framework.
\subsubsection{Formalization of Radiance Intervals}
The foundational property of the radiation field that allows for \glspl{rc} is the notion of splitting incoming radiation rays into distinct intervals that can be solved for separately (and iteratively combined). 
These intervals are called `radiance intervals', by convention from Sannikov~\cite{sannikovRadianceCascadesNovel}.

To prove this property, we begin with the characteristic form of the \gls{lbe} as
\begin{equation}
    \label{eq:lbe-characteristic-form}
    \dv{u}\psi^g\left(\mathbf{r}_0 + u\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
    + \Sigma_t^g\left(\mathbf{r}_0 + u\boldsymbol{\Omega}, \boldsymbol{\Omega}\right)\psi^g\left(\mathbf{r}_0 + u\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
    = 
    Q^g\left(\mathbf{r}_0 + u\boldsymbol{\Omega}, \boldsymbol{\Omega}\right).
\end{equation}
Before continuing, we first perform a change of variables from $u$ to $s$, such that $u=-s$ and $\frac{d}{du}=-\frac{d}{ds}$,~\cite[p.~210]{lewisComputationalMethodsNeutron1984a}.
This is done to solve `backwards' along each characteristic line; instead of solving for the contribution at $s$ from $\mathbf{r_0}$, we solve for the contribution at $\mathbf{r_0}$ from $s$.
Then, the characteristic form using this transform is
\begin{equation}
    \label{eq:lbe-cov-char-form}
    -\dv{s}\psi^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
    + \Sigma_t^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega}, \boldsymbol{\Omega}\right)\psi^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
    = 
    Q^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega}, \boldsymbol{\Omega}\right).
\end{equation}
This is an linear ordinary differential equation, and so it can be solved for by use of an integrating factor. 
We define the integrating factor as
\begin{equation}
    I = e^{-\int_0^s \dd{s'} \Sigma^g_t\left(\mathbf{r}_0 - s'\boldsymbol{\Omega},\boldsymbol{\Omega}\right)}.
\end{equation}
Henceforth, the independent variables are dropped purely for conciseness, and everything is assumed to be a function of $\mathbf{r}_0 - s'\boldsymbol{\Omega}$ and $\boldsymbol{\Omega}$ unless otherwise specified. 
Multiplying Eq.~\ref{eq:lbe-cov-char-form} by our integrating factor, we obtain
\begin{equation}
    \label{eq:lbe-if-characteristic-form}
    -e^{-\int_0^s \dd{s'} \Sigma^g_t}\dv{s}\psi^g
    + e^{-\int_0^s \dd{s'} \Sigma^g_t}\Sigma_t^g\psi^g
    = 
    e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g.
\end{equation}
The left hand side of this equation is the output of a product rule, specifically
\begin{equation}
    \dv{s}\left[-e^{-\int_0^s \dd{s'} \Sigma^g_t}\psi^g\right]
    =-e^{-\int_0^s \dd{s'} \Sigma^g_t}\dv{s}\psi^g
    + e^{-\int_0^s \dd{s'} \Sigma^g_t}\Sigma_t^g\psi^g.
\end{equation}
Then, we insert this relation into Eq.~\ref{eq:lbe-if-characteristic-form}, and integrate both sides with respect to $s$. We set the bounds for this integration to be from $a$ to $b$, such that $0\leq a\leq b\leq\tau$ where $\tau$ is the endpoint of the ray. These bounds are chosen instead of the typical $0$ to $\tau$, because we are only interested in the incoming radiation along this interval at $s=a$.

\begin{align}
    \dv{s}\left[-e^{\int_0^s \dd{s'} \Sigma^g_t}\psi^g\right] 
        &= e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g\notag\\
    \int_a^{b}\dd{s}\dv{s}\left[-e^{-\int_0^s \dd{s'} \Sigma^g_t}\psi^g\right]
        &= \int_a^{b} \dd{s}\,e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g
\end{align}

 For brevity, we define $\psi^g(x)=\psi^g\left(\mathbf{r}_0 - x\boldsymbol{\Omega},\boldsymbol{\Omega}\right)$. Evaluating the left hand side integral, rearranging, and solving for $\psi^g(a)$, we find
\begin{align}
    e^{-\int_0^{a} \dd{s'} \Sigma^g_t}\psi^g(a)
        &= e^{-\int_0^{b} \dd{s'} \Sigma^g_t}\psi^g(b) + \int_a^{b} \dd{s}\,e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g\notag\\
    \psi^g(a) 
        &= e^{\int_0^{a} \dd{s'} \Sigma^g_t} \left[
            e^{-\int_0^{b} \dd{s'} \Sigma^g_t}\psi^g(b) + \int_a^{b} \dd{s}\,e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g
        \right]\notag\\
         &= e^{\int_0^{a} \dd{s'} \Sigma^g_t - \int_0^{b} \dd{s'} \Sigma^g_t}\psi^g(b)
            + e^{\int_0^{a} \dd{s'} \Sigma^g_t} \int_a^{b} \dd{s}\,e^{-\int_0^s \dd{s'} \Sigma^g_t}Q^g
\end{align}

Now, because the exponential in front of the integral is a function of $s'$ and not $s$, it can be factored into the integral, and thus 
\begin{align}
        \psi^g(a) &= e^{-\int_a^{b} \dd{s'} \Sigma^g_t}\psi^g(b) + \int_a^{b} \dd{s}\,e^{\int_0^a \dd{s'} \Sigma^g_t-\int_0^{s} \dd{s'} \Sigma^g_t}Q^g\notag\\
    \label{eq:rc-interval-almost}
        &= e^{-\int_a^{b} \dd{s'} \Sigma^g_t}\psi^g(b) + \int_a^{b} \dd{s}\,e^{-\int_a^s \dd{s'} \Sigma^g_t}Q^g.
\end{align}
For completeness and clarity, we now expand out the independent variables in each term.
\begin{align}
    \label{eq:rc-interval-full}
    \begin{split}
    \psi^g\left(\mathbf{r}_0 - a\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        =\, &e^{-\int_a^{b} \dd{s'} \Sigma^g_t\left(\mathbf{r}_0 - s'\boldsymbol{\Omega},\boldsymbol{\Omega}\right)}\psi^g\left(\mathbf{r}_0 - b\boldsymbol{\Omega},\boldsymbol{\Omega}\right)\\
            &+ \int_a^{b} \dd{s}e^{-\int_a^s \dd{s'} \Sigma^g_t\left(\mathbf{r}_0 - s'\boldsymbol{\Omega},\boldsymbol{\Omega}\right)}Q^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
    \end{split}
\end{align}
Now, we formally define the transparency ($\beta^g_{a,b}$) and the radiance interval ($\psi^g_{a,b}$) as
\begin{align}
    \label{{eq:beta-and-rad-interval}}
    \beta^g_{a,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right) &= e^{-\int_a^b \dd{s'} \Sigma^g_t\left(\mathbf{r}_0 - s'\boldsymbol{\Omega}, \boldsymbol{\Omega}\right)}\\
    \psi^g_{a,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right)&= \int_a^{b} \dd{s}\,e^{-\int_a^s \dd{s'} \Sigma^g_t\left(\mathbf{r}_0 - s'\boldsymbol{\Omega}, \boldsymbol{\Omega}\right)}Q^g\left(\mathbf{r}_0 - s\boldsymbol{\Omega},\boldsymbol{\Omega}\right).
\end{align}
The naming `transparency' and `radiance interval' is used for clarity, as the original derivation of \glspl{rc} by Sannikov~\cite{sannikovRadianceCascadesNovel} used these terms.
Additionally, it should be noted that these definitions differ slightly from Sannikov's~\cite{sannikovRadianceCascadesNovel} in the arguments of the cross-section and source term, but are fundamentally identical. 
The notation used here is to be consistent with the standard \gls{moc} formulation within the field of computational neutron transport. 
Finally, we can insert our definitions for the transparency and radiance interval into Eq.~\ref{eq:rc-interval-full}, finding the simplified definition for the radiation contribution at $s=a$ from the interval $\left[a,b\right]$ as
\begin{equation}
    \label{eq:rad-contribution}
    \psi^g\left(\mathbf{r}_0 - a\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        = \beta^g_{a,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right)\psi^g\left(\mathbf{r}_0 - b\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        + \psi^g_{a,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right).
\end{equation}

\subsubsection{Validity of Radiance Interval Formulation}
To illustrate that this formulation is a valid method of breaking a ray into segments, we select an arbitrary ray broken into two segments. 
We define the interval ranges as $\left[a=0,b\right]$ and $\left[b,c=\tau\right]$.
Using equation~\ref{eq:rad-contribution} we define $\psi^g\left(\mathbf{r}_0,\boldsymbol{\Omega}\right)$ as 
\begin{align}
    \psi^g\left(\mathbf{r}_0,\boldsymbol{\Omega}\right)
        = \beta^g_{0,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right)\psi^g\left(\mathbf{r}_0 - b\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        + \psi^g_{0,b}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right).
\end{align}
Now, again using equation~\ref{eq:rad-contribution}, we define $\psi^g\left(\mathbf{r}_0 - b\boldsymbol{\Omega},\boldsymbol{\Omega}\right)$ as 
\begin{equation}
    \label{eq:rad-contribution}
    \psi^g\left(\mathbf{r}_0 - b\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        = \beta^g_{b,\tau}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right)\psi^g\left(\mathbf{r}_0 - \tau\boldsymbol{\Omega},\boldsymbol{\Omega}\right)
        + \psi^g_{b,\tau}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right).
\end{equation}
Inserting this definition into that of $\psi^g\left(\mathbf{r}_0,\boldsymbol{\Omega}\right)$, again dropping arguments for brevity, we find
\begin{align}
    \psi^g\left(\mathbf{r}_0,\boldsymbol{\Omega}\right) &= \beta^g_{0,b}
            \left[ \beta^g_{b,\tau}\psi^g\left(\tau\right) + \psi^g_{b,\tau} \right]
            + \psi^g_{0,b}\notag\\
        &= e^{-\int_0^b \dd{s'}\Sigma^g_t}
            \left[ e^{-\int_b^{\tau} \dd{s'}\Sigma^g_t}\psi^g\left(\tau\right) + \int_b^{\tau} \dd{s}\,e^{-\int_b^{s} \dd{s'} \Sigma^g_t}Q^g\right] +\psi^g_{b,\tau}\notag\\
        &= e^{-\int_0^{\tau} \dd{s'}\Sigma^g_t}\psi^g\left(\tau\right) + e^{-\int_0^b \dd{s'}\Sigma^g_t}\int_b^{\tau} \dd{s}\,e^{-\int_b^{s} \dd{s'} \Sigma^g_t}Q^g + \psi^g_{b,\tau}\notag\\ 
        &=e^{-\int_0^{\tau} \dd{s'}\Sigma^g_t}\psi^g\left(\tau\right) + \int_b^{\tau} \dd{s}\,e^{-\int_0^{s} \dd{s'} \Sigma^g_t}Q^g + \int_0^{b} \dd{s}\,e^{-\int_0^{s} \dd{s'} \Sigma^g_t}Q^g \notag\\
        &= e^{-\int_0^{\tau} \dd{s'}\Sigma^g_t}\psi^g\left(\tau\right) + \int_0^{\tau} \dd{s}\,e^{-\int_0^{s} \dd{s'} \Sigma^g_t}Q^g.
\end{align}

This finding is consistent with the long-characteristic solution that is the standard in \gls{moc}, and so we conclude that rays can be broken into radiance intervals as we have defined them. 

\subsubsection{Radiance Interval Merging}
The definition for $\psi^g\left(\mathbf{r}_0 - a\boldsymbol{\Omega},\boldsymbol{\Omega}\right)$ also defines how radiance intervals are combined to find the final solution at $\mathbf{r_0}$.
The radiance interval merging formula, written more generally than Eq.~\ref{eq:rad-contribution}, is
\begin{equation}
    \label{eq:rad-interval-merging}
    \psi^g_{i,i+1}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right) = \beta^g_{i,i+1}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right)\psi^g_{i+1,i+2}\left(\mathbf{r}_0,\boldsymbol{\Omega}\right)
        + \psi^g_{i,i+1}\left(\mathbf{r}_0, \boldsymbol{\Omega}\right),
\end{equation}
where the dummy index $i$ denotes the interval bounds. 
It is important to notice that two intervals can only be merged if they are directly adjacent: they must share a bound.
Finally, it should be evident that if a ray is broken into $n$ intervals, the solution to the ray is found through recursively merging the radiance intervals, collapsing towards $\mathbf{r_0}$.

\subsection{Cascades}
% Probes, cascades, cascades merging

% create image of cascades -- Liam

\section{Proposed Work}
This section discusses the implementation of \glspl{rc}, and our proposed work.

\subsection{Prerequisite Code Features}
Prior to implementing into a codebase, there a few features that must exist in order to implement \glspl{rc}. Additionally, there are highly-desired features that we think make a code more or less ideal to implement in, but are not explicitly required for implementation.

\subsubsection{Required Features}
\paragraph{Geometry Representation}
In the current form of \glspl{rc}, the spacing between probes of the same cascade must be identical. Because of this, the geometric representation in the code must be either structured rectilinear meshes or constructive solid geometry. If the geometric representation is a structured rectilinear mesh, then the vertices would be the centroids of probes. This is the representation used by Osborne for non-LTE radiative transfer~\cite{osborneRadianceCascadesNovel2025}. If the geometric representation is constructive solid geometry, then we would simply prescribe the probe centroids and would not be restricted by the mesh. Additionally, using constructive solid geometry would enable simple plug in to Monte Carlo codes down the line. 

\paragraph{Multigroup Cross Sections}
\glspl{rc} is a deterministic method, and so the energy dependence is discretized using either the multigroup approximation or some other discretization scheme (charged particle transport). As such, there must be some sort of cross section interface, allowing users to specify multigroup cross sections for geometric regions. 

\subsubsection{Desired Features}
\paragraph{Shared Memory Parallelism}
\glspl{rc} are optimized and well suited for shared memory parallel execution (trivially parallel). 
Specifically, radiance intervals can be calculated independently, and then after all intervals have been calculated, interval merging can be calculated independently with read-only access on `parent' probes. 
Unfortunately, distributed memory parallelism is a bit more challenging, and should be left for future work. Ideally, a code base would have some notion of shared memory parallelism already existing, especially GPU based parallelism.
This would be in the form of OpenMP or CUDA, or ideally a general parallelism interface like OneAPI, Kokkos, RAJA, etc. 
The benefits of using a general interface are that they are externally maintained and updated, interface with all types of GPUs (NVIDIA, AMD, Intel...) and CPUs (Intel, AMD...) with no additional user effort or code written, and would be updated to reflect the state of the industry (e.g. new GPU company comes out).
Among all of the general parallelism interfaces, Kokkos seems to be the front runner because of its simple interface, large user community, highly active development team, large device support, and backing from the Linux foundation.
The next best would be RAJA, which has a smaller community overall and less backing, but has been shown to outperform Kokkos for simple instruction programs~\cite{}.%https://www.osti.gov/servlets/purl/2305595

\paragraph{Simple Code Base}
Ideally, the code base would be relatively simple to develop in. 
This means the code for the executable would be written in one language, and not, for example, half-python and half-c++ (SWIG, Cython). 
In our opinion (Nathan), SWIG and Cython drastically worsen the complexity of the build system, without much of a real payoff in user experience. 
A system like OpenMC's, where there is a python interface for generating input files but the actual code execution occurs entirely in C++, is desired.

\paragraph{} % Not sure where this goes
It is imperative in the growing use and capabilities of graphical processing units (GPUs) that any and all commercial implementations of \glspl{rc} parallelize using GPUs.
It has been shown~\cite{sannikovRadianceCascadesNovel,osborneRadianceCascadesNovel2025} that \glspl{rc} scales extremely well in parallel, and indeed GPUs are manufactured to handle the ray-tracing needs of the method.




\subsection{Radiance Cascades Implementation}

\subsubsection{Toy Problem}
Rather than jumping in to implementing \glspl{rc} in the general case, we propose to start with a simple implementation of \textit{no more than two} ``toy'' problems, where we choose very simple transport problems in 2D to implement with either a Python or C++ script.
The purpose of this is purely educational, and it will do two things:
\begin{enumerate}
    \item Create an opportunity to practice programming \glspl{rc} on a small problem before jumping to generalized code.
    \item Show early results for the method applied to neutronics (internally, though it may make a cool LinkedIn post or something\ldots).
\end{enumerate}

% OpenMoC, OpenCSG (separating from OpenMC -- would need to work with developers)
\subsubsection{Implementation Target}
There were four codes that we investigated as possible implementation points.
These four codes were OpenMC, OpenSN, DexRT, and OpenMOC.
\paragraph{OpenMC}
\paragraph{OpenSN}
\paragraph{DexRT}
\paragraph{OpenMOC}

\subsubsection{Implementation Outline}
% Long time implementation outline
% - maintenance required
% - updates planned
% - planned implementation goals (forward solve, 2D, source iteration, neutron only, multiplying and fixed source...)

\subsection{Benchmarks}
Benchmark cases for \glspl{rc} must be chosen to specifically show the advantages of the method and directly test for known problems in other methods, such as ray-effects in \glspl{sn}.
To be considered successful, we will need to implement \glspl{rc} in such a way that not only converges to the correct solution, but can also do so faster than proven methods such as \glspl{sn}.
Or, alternatively, must be proven to scale well using GPU parallelism.
We propose the following benchmark cases be used for the development and testing of \glspl{rc}.

The application of \glspl{rc} to the \glspl{bte} has been largely proven by Osborne and Sannikov~\cite{osborneRadianceCascadesNovel2025}, though with a particular application to photon transport in astrophysics.
There are two main differences between this application and ours:
\begin{enumerate}
    \item Neutron transport simulations are typically focused on length scales in the centimeters to meters, not kilometers and light-years.\label{first difference}
    \item The source term is dependent on the flux in multiplying (fission) media.\label{second difference}
\end{enumerate}

\Cref{first difference} will be straightforward to show, as there are many benchmarks that allow for testing neutron streaming.
One such set, known as the Kobayashi benchmarks~\cite{kobayashi3DRADIATIONRANSPORT2000}, has become an industry standard and has been used consistently in modern codes, such as the \glspl{sn} code Denovo from Oak Ridge National Laboratory~\cite{evansDenovoNewThreeDimensional2010b}.
They look to test streaming through voids from a fixed source into a non-multiplying material.

These benchmarks consist of three geometries:
\begin{enumerate}
    \item A source surrounded by a cubic void.
    \item A source with a vertical (chimney-like) void.
    \item A source with a ``dog leg''\footnote{Yes, that is the actual name in the paper.} void duct.
\end{enumerate}
% Add images!
The surrounding non-void region is either strictly absorbing or \%50 absorbing with \%50 scattering (of the total cross section).

The ultimate goal will be to report on \glspl{rc}'s capabilities on the 3D problems as they were originally published.
However, we will propose to start with 2D ``flattened'' versions of these problems for a proof-of-concept internally, then move on to 3D implementation.

\Cref{second difference}, however, is the more interesting and relevant problem to tackle for a proof-of-concept, and thus will make up the bulk of the work for benchmark problems.

\paragraph{Liam}
C5G7 (multiplying)

\subsection{Discussion Points}
This section highlights specific ideas we have had that could fit into both future work and first implementation.

\paragraph{Standalone CSG Package}
A standalone constructive solid geometry package, shared by major open source Monte Carlo codes such as OpenMC and MCDC, would greatly support the development of deterministic solvers intended to plug into Monte Carlo codes for generating variance-reduction parameters.
The idea is that deterministic-method developers could simply import this package and focus solely on implementing their solver, while the shared CSG library would handle geometry as well as both continuous-energy (CE) and multigroup (MG) cross-section representations.
Such an approach would significantly accelerate the development of \glspl{rc} codes, whether integrated into OpenMOC or another code, by eliminating the need to independently update/implement and maintain CSG and MGXS infrastructure within the \gls{rc} codebase.

\paragraph{Source Representation}
A major limitation to \gls{moc} (and \gls{trrm}) is the required use of source regions.
This limitation is entirely because MOC solvers do not know the angular/scalar flux at discrete points throughout the problem domain. \glspl{rc} do not suffer this limitation, and as such do not necessarily rely on source regions.
Instead, the source along each radiance interval can be computed as a continuous function by interpolating from nearby C0 probes.
This will likely add computational cost, as now the source function would need to be numerically integrated, but might result in significant improvements in accuracy.

\section{Future Work}
\subsection{Unstructured Probe Placement and Improved Interpolation}
Liam's scratch thoughts:
\begin{itemize}
    \item Numerous meshing algorithms exist that can place nodes within the domain of arbitrary meshes (such as \texttt{gmsh}).
    \item The requirements of \glspl{rc} lie in the spacing between probes with regard to their angular resolution. 
    As of the writing of this, it is understood that each increase in cascade ``level'' results in a doubling of the spatial distance.
    It should therefore be very straightforward to use a mesh generator with a user-set minimum spatial discretization for cascade 0, then the generator can place the probes for all higher cascades by doubling a global mesh parameter. 
    The parameter needs to ensure that this is the \textit{maximum} distance between probes (nodes) to ensure the penumbra criteria are satisfied.
    \item This admittedly sounds a lot like using finte element-like basis functions to interpolate between probes (nodes), though without the complicated basis functions -- we only need to use two probes to linearly interpolation, then three probes for quadratic, etc. I wonder, then if we could use something like B-splines to get high-accuracy interpolation between notes\ldots This may be too complicated, but the point is that increasing the interpolation accuracy should be mathematically straightforward, if not computationally obnoxious.
    \item After meshing, each probe will have to hold information about the angular flux (including all of the its directions) \emph{and the nodes which it will interpolate between}. This should be as simple as using a search algorithm to find the nearest probes\ldots Or we could just use information from FEM meshers and ignore any information about the basis functions\ldots
\end{itemize}

\subsection{Adjoint Solver}
One of the endgoals of Radiance cascades is to generate weight windows for variance reduction in a Monte Carlo code. To do so, an adjoint solve mode must be implemented. 

\subsection{Acceleration Methods}
There are various methods employed in deterministic neutron transport methods for convergence acceleration that could be used for \glspl{rc}. Specific methods I think would be interesting to investigate are \gls{cmfd}, \gls{dsa}, and \gls{tsa}. \gls{cmfd} has already been used for \gls{moc} codes (and is implemented in OpenMOC and OpenMC) and has proven to be a great accelerator. \gls{dsa} (from what I can tell) is a super effective method for accelerating source iteration, but is only effective for highly diffusive problems/regions. \gls{tsa} (from what I can tell) is a more robust method for accelerating source iteration, is well suited for highly anisotropic scattering problems/regions and sparse/void/near-void problems / regions; at added computational cost compared to DSA. 

\subsection{Problem Sparsity}
Osborne~\cite{osborneRadianceCascadesNovel2025, osborneSimpleRayAcceleration2025} discusses how in non-LTE radiation transport, many problems are very sparse, and so a lot of computation is wasted on void regions. This is similair to space applications, shut down dose rate calculations, and in general just charged particle transport problems. Osborne had some interesting ideas, namely using sparse graphs like VDB (which is a large package we could bring in and not worry about maintenance) and prefiltering void probes out of the problem. The prefiltering allows us to skip computing probes that we know do not contribute, drastically saving on compute cost, and the sparse rooted graphs efficiently store linked probes minimizing look up times when merging. This needs to be investigated a lot more before formalizing though, unsure as to how to filter out probes.

\subsection{Charged Particle Transport}
Nathan's work will be in charged particle transport, so a \glspl{rc} formulation for charged particle transport will be required. This is in future work because of the added complexity of the Boltzmann-Fokker-Planck equation compared to the linear Boltzmann equation.