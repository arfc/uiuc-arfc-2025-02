
A new method for real-time global illumination called \acrfull{rcs} emerged recently\footnote{This is intentionally vague, as the paper written was not dated nor published in a journal. It is available freely on GitHub.} in the paper ``Radiance Cascades: A Novel Approach to Calculating Global Illumination'' by Alexander Sannikov~\cite{sannikovRadianceCascadesNovel}.
Sannikov, a video game developer, proposed a new data structure he termed ``radiance cascades'' that more effectively calculates and stores radiance field information by decomposing the domain into near- and far-field regions.
This idea is based on a simple observation: to resolve the radiance from an emitter, one needs to have higher spatial resolution near the object but higher angular resolution far from it.

Another integral concept of the technique is ray construction.
Instead of explicitly casting rays, each probe (within each cascade) is assigned a spherical ``shell'' region and angular discretization, representing the portion of the domain contributing to that probeâ€™s radiance.
The thickness of this shell is termed the ``radiance interval'' and is one of the foundational principles of the method.
Thus, once a cascade has evaluated the contributions to each probe within its respective radiance interval, these intervals can be combined into reconstructed rays via interpolation when needed.

Sannikov claims that the method enables, for practical all purposes, infinitely many rays to be constructed at finite computational cost.
Indeed, he shows that the total memory required to store an infinite number of cascades is less than a constant, that constant being exactly equal to twice the amount of memory required to store the first cascade.
This holds for \textit{both} 2D and 3D problems.
As in neutronics methods like the \acrlong{moc} and its relative, the \acrlong{trrm}, scalability is constrained by the memory demands associated with casting a sufficiently dense set of rays to resolve far-field solutions.
Although Sannikov~\cite{sannikovRadianceCascadesNovel} presents a promising approach, he notes that storing only the first cascade is effectively equivalent to discretizing the entire domain, which can be prohibitive for sufficiently large domains or dense probe configurations. 
In practice, the benefits of the technique emerge only after allocating approximately twice the memory of the finest spatial discretization because the incremental memory cost of subsequent cascades decreases exponentially.

The most relevant work to this project proposal is that written by Osborne and Sannikov entitled ``Radiance cascades: a novel high-resolution formal solution for multidimensional non-LTE radiative transfer''~\cite{osborneRadianceCascadesNovel2025}.
In this paper, the authors apply \acrlong{rcs} to radiative transfer in astrophysics.
Similar to deterministic neutron transport methods, the discrete ordinates method has dominated as the method-of-choice, and has likewise struggled with ray effects.
Unlike terrestrial neutronics, astrophysics often cannot take advantage of Monte Carlo methods because of massive length scales, and these scales likewise greatly degrade the \acrshort{sn} solution far from the source.
Achieving accurate solutions therefore requires extremely high angular resolution, but the computational needs scale linearly with the number of angular quadrature points.

Osborne revisits the claim of infinite rays constructed at finite cost.
He observes that this asymptotic scaling breaks down before the infinite-ray limit is reached, but emphasizes that, so long as the penumbra criterion\footnote{More on this term in \cref{subsec:penumbra-criterion}.} holds, ``the integration of the radiation field at high spatial and angular resolution [is] far cheaper than could be obtained with any traditional ray-casting approach.''
Additionally, the computational cost is dependent on the length of the radiance interval, and for higher cascades, these intervals can be considerably longer than those of lower cascades.
Lastly, the scaling laws introduced by~\cite{sannikovRadianceCascadesNovel} and~\cite{osborneRadianceCascadesNovel2025} are dependent on the so-called ``branching factor,'' which controls the number of rays computed for each cascade.
It is mentioned that more complex branching strategies can be applied in 3D to take advantage of the second angular dimension, potentially leading to improved scaling.
This hypothesis was not explored further in Osborne's paper.

The most significant contribution to \acrlong{rcs} in~\cite{osborneRadianceCascadesNovel2025} is the so-called bilinear fix.
One weakness of \acrshort{rcs} as it was introduced in~\cite{sannikovRadianceCascadesNovel} is ringing artifacting.
The fix eliminates these numerical errors by correctly interpolating the source contributions from the next highest cascade.
An overview of this fix is provided in \cref{subsec:bilinear-fix}.

The final relevant paper is entitled ``Holographic Radiance Cascades for 2D Global Illumination''~\cite{freemanHolographicRadianceCascades2025}. 
In this work, the authors reformulate the original \acrlong{rcs} approach to reduce resolution in only a single direction as the cascades progress. 
This modification both improves shadow resolution by limiting the diffusion inherent to the classical \acrlong{rcs} formulation and introduces an effective acceleration structure. 
The results demonstrate particular promise for radiation shielding applications, where accurately resolving shadowed regions is critical.

